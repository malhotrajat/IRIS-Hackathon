{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRIS Online Review Prediction Model\n",
    "The task of this hackathon challenge is to create a predictive model to classify online electronics reviews into five categories, ranking from 1 (lowest) to 5 (highest). Both train sets and test sets are provided. We recommend the following guidelines in preparing the data set, training/testing the model, and applying it to the final test set. \n",
    "\n",
    "1. Resampling the dataset into more balanced dataset due to the nature of online reviews.\n",
    "2. Feature engineering - cleansing and expanding the data set into a set of features that text mining algorithms expect.\n",
    "3. Testing the model by cross validation.\n",
    "4. Apply the model to a test set and report the results for scoring.\n",
    "\n",
    "This document aims at explaing step by step the concepts and procedures in the making of the predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the entire training set into memory and train the model based on all of it has two major downsides:\n",
    "1. The sheer volume (1.6 million rows) of the data would incur high computational cost. Given the time constraint in the hackathon, such computational load is inhibitive.\n",
    "2. The data set is unbalanced by nature. Most reviews collected are positive (4-5), while neutral and below (1-3) are much rarer. Training the model on such data set will likely lead to biased prediction. The histogram shows the unbalanced nature of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.loc[1:10000,:]\n",
    "num_bins = 5\n",
    "n, bins, patches = plt.hist(train['Rating'], num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by counting the number of words and number of characters in each reviews, as well as the average length of words. These three new features are appended to the training data set as new features. The techniques are self-explanatory in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am using this with a Nook HD+. It works as d...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ReviewText  word_count\n",
       "1  I'm a professional OTR truck driver, and I bou...         446\n",
       "2  Well, what can I say.  I've had this unit in m...         888\n",
       "3  Not going to write a long review, even thought...         449\n",
       "4  I've had mine for a year and here's what we go...         202\n",
       "5  I am using this with a Nook HD+. It works as d...          22"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['word_count'] = train['ReviewText'].apply(lambda x: len(str(x).split(\" \")))\n",
    "train[['ReviewText','word_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>2175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>4607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>2246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am using this with a Nook HD+. It works as d...</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ReviewText  char_count\n",
       "1  I'm a professional OTR truck driver, and I bou...      2175.0\n",
       "2  Well, what can I say.  I've had this unit in m...      4607.0\n",
       "3  Not going to write a long review, even thought...      2246.0\n",
       "4  I've had mine for a year and here's what we go...      1076.0\n",
       "5  I am using this with a Nook HD+. It works as d...       109.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['char_count'] = train['ReviewText'].str.len() ## this also includes spaces\n",
    "train[['ReviewText','char_count']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>4.051522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>4.397163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>4.004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>4.331683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am using this with a Nook HD+. It works as d...</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ReviewText  avg_word\n",
       "1  I'm a professional OTR truck driver, and I bou...  4.051522\n",
       "2  Well, what can I say.  I've had this unit in m...  4.397163\n",
       "3  Not going to write a long review, even thought...  4.004454\n",
       "4  I've had mine for a year and here's what we go...  4.331683\n",
       "5  I am using this with a Nook HD+. It works as d...  4.000000"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_word(sentence):\n",
    "  #print(sentence)\n",
    "  sentence = str(sentence)\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "train['avg_word'] = train['ReviewText'].apply(lambda x: avg_word(x))\n",
    "train[['ReviewText','avg_word']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the major forms of pre-processing is to filter out useless data. In natural language processing, useless words (data), are referred to as stop words. A stop word is a commonly used word (such as “the”, “a”, “an”, “in”). The algorithm below identifies such words in English and count the number of occurences in each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am using this with a Nook HD+. It works as d...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ReviewText  stopwords\n",
       "1  I'm a professional OTR truck driver, and I bou...        177\n",
       "2  Well, what can I say.  I've had this unit in m...        362\n",
       "3  Not going to write a long review, even thought...        196\n",
       "4  I've had mine for a year and here's what we go...         86\n",
       "5  I am using this with a Nook HD+. It works as d...          8"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#print(train['ReviewText'])\n",
    "#train['ReviewText',:] = str(train['ReviewText',:])\n",
    "\n",
    "train['stopwords'] = train['ReviewText'].apply(lambda x: len([x for x in str(x).split() if x in stop_words]))\n",
    "train[['ReviewText','stopwords']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am using this with a Nook HD+. It works as d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ReviewText  hastags\n",
       "1  I'm a professional OTR truck driver, and I bou...        0\n",
       "2  Well, what can I say.  I've had this unit in m...        0\n",
       "3  Not going to write a long review, even thought...        0\n",
       "4  I've had mine for a year and here's what we go...        0\n",
       "5  I am using this with a Nook HD+. It works as d...        0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['hastags'] = train['ReviewText'].apply(lambda x: len([x for x in str(x).split() if x.startswith('#')]))\n",
    "train[['ReviewText','hastags']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewText</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a professional OTR truck driver, and I bou...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, what can I say.  I've had this unit in m...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not going to write a long review, even thought...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've had mine for a year and here's what we go...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am using this with a Nook HD+. It works as d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ReviewText  numerics\n",
       "1  I'm a professional OTR truck driver, and I bou...         7\n",
       "2  Well, what can I say.  I've had this unit in m...         7\n",
       "3  Not going to write a long review, even thought...         6\n",
       "4  I've had mine for a year and here's what we go...         1\n",
       "5  I am using this with a Nook HD+. It works as d...         0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['numerics'] = train['ReviewText'].apply(lambda x: len([x for x in str(x).split() if x.isdigit()]))\n",
    "train[['ReviewText','numerics']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making every review lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    i'm a professional otr truck driver, and i bou...\n",
       "2    well, what can i say. i've had this unit in my...\n",
       "3    not going to write a long review, even thought...\n",
       "4    i've had mine for a year and here's what we go...\n",
       "5    i am using this with a nook hd+. it works as d...\n",
       "Name: ReviewText, dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ReviewText'] = train['ReviewText'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "train['ReviewText'].head()\n",
    "# Translate here later\n",
    "#translateDiction = pd.read_csv('Contractions.csv')\n",
    "#print(translateDiction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    im a professional otr truck driver and i bough...\n",
       "2    well what can i say ive had this unit in my tr...\n",
       "3    not going to write a long review even thought ...\n",
       "4    ive had mine for a year and heres what we got ...\n",
       "5    i am using this with a nook hd it works as des...\n",
       "Name: ReviewText, dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['ReviewText'] = train['ReviewText'].str.replace('[^\\w\\s]','')\n",
    "train['ReviewText'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    im professional otr truck driver bought tnd 70...\n",
       "2    well say ive unit truck four days prior garmin...\n",
       "3    going write long review even thought unit dese...\n",
       "4    ive mine year heres got tries route non truck ...\n",
       "5    using nook hd works described hd picture samsu...\n",
       "Name: ReviewText, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "train['ReviewText'] = train['ReviewText'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in stop))\n",
    "train['ReviewText'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common word removal (Top N, user discretion required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(train['ReviewText']).split()).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    im professional otr truck driver bought tnd 70...\n",
       "2    well say ive unit truck four days prior garmin...\n",
       "3    going write long review even thought unit dese...\n",
       "4    ive mine year heres got tries route non truck ...\n",
       "5    using nook hd works described hd picture samsu...\n",
       "Name: ReviewText, dtype: object"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "train['ReviewText'] = train['ReviewText'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['ReviewText'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rare Words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(train['ReviewText']).split()).value_counts()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    im professional otr truck driver bought tnd 70...\n",
       "2    well say ive unit truck four days prior garmin...\n",
       "3    going write long review even thought unit dese...\n",
       "4    ive mine year heres got tries route non truck ...\n",
       "5    using nook hd works described hd picture samsu...\n",
       "Name: ReviewText, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = list(freq.index)\n",
    "train['ReviewText'] = train['ReviewText'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['ReviewText'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    in professional or truck driver bought and 700...\n",
       "Name: ReviewText, dtype: object"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "train['ReviewText'][:1].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['going', 'write', 'long', 'review', 'even', 'thought', 'unit', 'deserves', 'ive', 'driven', 'well', '1mil', 'miles', 'done', 'routing', 'pretty', 'know', 'whats', 'fastest', 'shortest', 'using', 'basic', 'garmin', 'past', 'three', 'years', 'gps', 'unit', 'theyll', 'trouble', 'let', 'really', 'excited', 'unit', 'due', 'size', 'features', 'allot', 'grafics', 'screen', 'info', 'thats', 'usefull', 'basic', 'item', 'lacking', 'gps', 'tracking', 'gave', 'unit', 'allot', 'leadway', 'mistakes', 'due', 'fact', 'allot', 'cool', 'stuff', 'ability', 'track', 'route', 'even', 'close', 'basic', 'garmin', 'could', 'due', 'prossesor', 'installed', 'tnd', '700', '10', 'years', 'old', 'example', 'needed', 'make', 'simple', 'route', 'change', 'ie', 'town', 'next', 'street', 'due', 'fact', 'couldnt', 'make', 'turn', 'street', 'blocked', 'take', 'tnd', '700', 'upwards', '45', 'seconds', 'minute', 'half', 'reroute', 'im', 'sitting', 'stop', 'light', 'waiting', 'directions', 'waiting', 'long', 'cars', 'backside', 'didnt', 'make', 'happy', 'problem', 'happened', 'evertime', 'reroute', 'weather', 'simple', 'street', 'change', 'major', 'highway', 'change', 'also', 'time', 'turned', 'unit', 'take', 'twice', 'long', 'boot', 'least', 'dozen', 'times', 'week', 'put', 'wrong', 'roads', 'made', 'wrong', 'turn', 'got', 'self', 'lostie', 'take', 'left', 'xyz', 'street', 'ones', 'drive', 'way', 'turn', 'left', '800', 'yards', 'turn', 'less', '10', 'feet', 'away', 'might', 'think', 'conjested', 'city', 'situation', 'might', 'little', 'mixed', 'country', 'twice', 'put', '126', 'bridges', 'im', '136', 'course', 'made', 'sure', 'truck', 'setting', 'supposed', 'also', 'updated', 'os', 'versionvia', 'rand', 'mcnally', 'expected', 'alot', 'unit', 'got', 'unit', 'field', 'tested', 'people', 'drive', 'allot', 'many', 'route', 'mistakes', 'going', 'back', 'basic', 'garmin', 'isnt', 'complaints', 'three', 'friends', 'bought', 'unit', 'complaints', 'us', 'returned', 'units'])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('punkt')\n",
    "\n",
    "TextBlob(train['ReviewText'][3]).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    im profession otr truck driver bought tnd 700 ...\n",
       "Name: ReviewText, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "train['ReviewText'][:1].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    im professional otr truck driver bought tnd 70...\n",
       "2    well say ive unit truck four day prior garmin ...\n",
       "3    going write long review even thought unit dese...\n",
       "4    ive mine year here got try route non truck rou...\n",
       "5    using nook hd work described hd picture samsun...\n",
       "Name: ReviewText, dtype: object"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('wordnet')\n",
    "from textblob import Word\n",
    "train['ReviewText'] = train['ReviewText'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train['ReviewText'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
    "texts = train['ReviewText'].tolist()\n",
    "tagged_texts = pos_tag_sents(map(word_tokenize, texts))\n",
    "\n",
    "train['POS'] = tagged_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    [('im', 'JJ'), ('professional', 'JJ'), ('otr',...\n",
      "2    [('well', 'RB'), ('say', 'VB'), ('ive', 'JJ'),...\n",
      "3    [('going', 'VBG'), ('write', 'RB'), ('long', '...\n",
      "4    [('ive', 'JJ'), ('mine', 'NN'), ('year', 'NN')...\n",
      "5    [('using', 'VBG'), ('nook', 'NN'), ('hd', 'NN'...\n",
      "Name: ner, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('words')\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "a = [0] * len(train['ReviewText'])\n",
    "for i in range(len(train['ReviewText'])):\n",
    "    temp = word_tokenize(str(train.iloc[i,0]))\n",
    "    a[i] = str(pos_tag(temp))\n",
    "\n",
    "temp2 = ne_chunk(a)\n",
    "#len(temp2)\n",
    "train['ner']=ne_chunk(a)\n",
    "print(train['ner'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Ngrams'] = train['ReviewText'].apply(lambda x: TextBlob(x).ngrams(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,2),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(train['ReviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_bow).to_csv(\"train_bag_of_words.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train_Features.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
